version: '3.8'

services:
  llm-api:
    build: .
    container_name: llm-session-api
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - XDG_DATA_HOME=/root/.local/share
    volumes:
      # Persistence
      - ./session_data:/root/.local/share/LLMSession
      # Error Screenshots
      - ./output:/app/output
    ports:
      - "8080:8000"
      - "5900:5900" # VNC Port
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
